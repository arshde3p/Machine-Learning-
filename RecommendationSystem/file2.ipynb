{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name                        Insitute      Batch  \\\n",
      "0       Abhi     ABC Institute of Technology  2010-2014   \n",
      "1       Suri     DEF Institute of Technology  2011-2015   \n",
      "2   GS Sidhu  Danish Institute of Technology  2012-2016   \n",
      "3    Prakash     DEF Institute of Technology  2011-2015   \n",
      "4       Simi  Danish Institute of Technology  2010-2014   \n",
      "5       Agam     ABC Institute of Technology  2012-2016   \n",
      "6     Kanish  Danish Institute of Technology  2010-2014   \n",
      "7      Sahil     ABC Institute of Technology  2012-2016   \n",
      "8        Adi     DEF Institute of Technology  2011-2015   \n",
      "9       Shah     DEF Institute of Technology  2011-2015   \n",
      "10       Sam     DEF Institute of Technology  2011-2015   \n",
      "11     sehaj     DEF Institute of Technology  2011-2015   \n",
      "12     karan     DEF Institute of Technology  2011-2015   \n",
      "13      atul     DEF Institute of Technology  2011-2015   \n",
      "14     rohit     DEF Institute of Technology  2011-2015   \n",
      "\n",
      "                                       Branch Presently doing  \\\n",
      "0            Computer Science and Engineering             Job   \n",
      "1            Computer Science and Engineering             Job   \n",
      "2                      Mechanical Engineering    Higher Study   \n",
      "3                           Civil Engineering             Job   \n",
      "4            Computer Science and Engineering             Job   \n",
      "5                      Mechanical Engineering    Higher Study   \n",
      "6   Electronics and Communication Engineering    Higher Study   \n",
      "7            Computer Science and Engineering             Job   \n",
      "8                      Mechanical Engineering             Job   \n",
      "9            Computer Science and Engineering             Job   \n",
      "10           Computer Science and Engineering             Job   \n",
      "11           Computer Science and Engineering             Job   \n",
      "12           Computer Science and Engineering             Job   \n",
      "13           Computer Science and Engineering             Job   \n",
      "14           Computer Science and Engineering             Job   \n",
      "\n",
      "            Institute/Organisation         Specialisation              Email  \\\n",
      "0       Vmm Technologies Pvt. Ltd.                web dev     abhi1@mail.com   \n",
      "1        UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "2   Danish Institute of Technology      Automobile design     sidhu@mail.com   \n",
      "3      L&B Constructions Pvt. Ltd.        Mega Structures  prakash@maill.com   \n",
      "4        Inte Processors Pvt. Ltd.  Computer Architecture      simi@mail.com   \n",
      "5      Lal Institute of Technology        Induction Motor      agam@mail.com   \n",
      "6      Lal Institute of Technology  Communication systems    kanish@mail.com   \n",
      "7        UP Technologies Pvt. Ltd.       Machine Learning     sahil@mail.com   \n",
      "8       Avon Automobiles Pvt. Ltd.      Automobile design       adi@mail.com   \n",
      "9        UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "10       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "11       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "12       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "13       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "14       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "\n",
      "   Password  \n",
      "0     abhi1  \n",
      "1      suri  \n",
      "2     sidhu  \n",
      "3   prakash  \n",
      "4      simi  \n",
      "5      agam  \n",
      "6    kanish  \n",
      "7     shail  \n",
      "8       adi  \n",
      "9      suri  \n",
      "10     suri  \n",
      "11     suri  \n",
      "12     suri  \n",
      "13     suri  \n",
      "14     suri  \n",
      "We have 15 student records in the data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.plotly as py\n",
    "# import cufflinks\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "df = pd.read_excel('hacknitj dataset.xlsx')\n",
    "print(df)\n",
    "print('We have', len(df), 'student records in the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Specialisation  count\n",
      "0             dev      8\n",
      "1         android      7\n",
      "2      automobile      2\n",
      "3          design      2\n",
      "4             web      1\n",
      "5            mega      1\n",
      "6      structures      1\n",
      "7        computer      1\n",
      "8    architecture      1\n",
      "9       induction      1\n",
      "10          motor      1\n",
      "11  communication      1\n",
      "12        systems      1\n",
      "13        machine      1\n",
      "14       learning      1\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(df['Specialisation'], 20)\n",
    "df1 = pd.DataFrame(common_words, columns = ['Specialisation' , 'count'])\n",
    "# df1.groupby('Specialisation').sum()['count'].sort_values().scatter(kind='barh', yTitle='Count', linecolor='black', title='Top 20 words in Specialisation description before removing stop words')\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(df['Specialisation'], 20)\n",
    "df3 = pd.DataFrame(common_words, columns = ['Specialisation' , 'count'])\n",
    "# df3.groupby('Specialisation').sum()['count'].sort_values(ascending=False).iplot(kind='bar', yTitle='Count', linecolor='black', title='Top 20 bigrams in hotel description before removing stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Specialisation  count\n",
      "0            android dev      7\n",
      "1      automobile design      2\n",
      "2                web dev      1\n",
      "3        mega structures      1\n",
      "4  computer architecture      1\n",
      "5        induction motor      1\n",
      "6  communication systems      1\n",
      "7       machine learning      1\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(df['Specialisation'], 20)\n",
    "df4 = pd.DataFrame(common_words, columns = ['Specialisation' , 'count'])\n",
    "# df4.groupby('Specialisation').sum()['count'].sort_values(ascending=False).iplot(kind='bar', yTitle='Count', linecolor='black', title='Top 20 bigrams in hotel description After removing stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Specialisation  count\n",
      "0            android dev      7\n",
      "1      automobile design      2\n",
      "2                web dev      1\n",
      "3        mega structures      1\n",
      "4  computer architecture      1\n",
      "5        induction motor      1\n",
      "6  communication systems      1\n",
      "7       machine learning      1\n"
     ]
    }
   ],
   "source": [
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4318f93321e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mwords_freq\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwords_freq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcommon_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_n_trigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Specialisation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdf6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Specialisation'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# df6.groupby('desc').sum()['count'].sort_values(ascending=False).iplot(kind='bar', yTitle='Count', linecolor='black', title='Top 20 trigrams in hotel description after removing stop words')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-4318f93321e9>\u001b[0m in \u001b[0;36mget_top_n_trigram\u001b[1;34m(corpus, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_top_n_trigram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mbag_of_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwords_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \"\"\"\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1058\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m    990\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(df['Specialisation'], 20)\n",
    "df6 = pd.DataFrame(common_words, columns = ['Specialisation' , 'count'])\n",
    "# df6.groupby('desc').sum()['count'].sort_values(ascending=False).iplot(kind='bar', yTitle='Count', linecolor='black', title='Top 20 trigrams in hotel description after removing stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['Specialisation_clean'] = df['Specialisation'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name                        Insitute      Batch  \\\n",
      "0       Abhi     ABC Institute of Technology  2010-2014   \n",
      "1       Suri     DEF Institute of Technology  2011-2015   \n",
      "2   GS Sidhu  Danish Institute of Technology  2012-2016   \n",
      "3    Prakash     DEF Institute of Technology  2011-2015   \n",
      "4       Simi  Danish Institute of Technology  2010-2014   \n",
      "5       Agam     ABC Institute of Technology  2012-2016   \n",
      "6     Kanish  Danish Institute of Technology  2010-2014   \n",
      "7      Sahil     ABC Institute of Technology  2012-2016   \n",
      "8        Adi     DEF Institute of Technology  2011-2015   \n",
      "9       Shah     DEF Institute of Technology  2011-2015   \n",
      "10       Sam     DEF Institute of Technology  2011-2015   \n",
      "11     sehaj     DEF Institute of Technology  2011-2015   \n",
      "12     karan     DEF Institute of Technology  2011-2015   \n",
      "13      atul     DEF Institute of Technology  2011-2015   \n",
      "14     rohit     DEF Institute of Technology  2011-2015   \n",
      "\n",
      "                                       Branch Presently doing  \\\n",
      "0            Computer Science and Engineering             Job   \n",
      "1            Computer Science and Engineering             Job   \n",
      "2                      Mechanical Engineering    Higher Study   \n",
      "3                           Civil Engineering             Job   \n",
      "4            Computer Science and Engineering             Job   \n",
      "5                      Mechanical Engineering    Higher Study   \n",
      "6   Electronics and Communication Engineering    Higher Study   \n",
      "7            Computer Science and Engineering             Job   \n",
      "8                      Mechanical Engineering             Job   \n",
      "9            Computer Science and Engineering             Job   \n",
      "10           Computer Science and Engineering             Job   \n",
      "11           Computer Science and Engineering             Job   \n",
      "12           Computer Science and Engineering             Job   \n",
      "13           Computer Science and Engineering             Job   \n",
      "14           Computer Science and Engineering             Job   \n",
      "\n",
      "            Institute/Organisation         Specialisation              Email  \\\n",
      "0       Vmm Technologies Pvt. Ltd.                web dev     abhi1@mail.com   \n",
      "1        UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "2   Danish Institute of Technology      Automobile design     sidhu@mail.com   \n",
      "3      L&B Constructions Pvt. Ltd.        Mega Structures  prakash@maill.com   \n",
      "4        Inte Processors Pvt. Ltd.  Computer Architecture      simi@mail.com   \n",
      "5      Lal Institute of Technology        Induction Motor      agam@mail.com   \n",
      "6      Lal Institute of Technology  Communication systems    kanish@mail.com   \n",
      "7        UP Technologies Pvt. Ltd.       Machine Learning     sahil@mail.com   \n",
      "8       Avon Automobiles Pvt. Ltd.      Automobile design       adi@mail.com   \n",
      "9        UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "10       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "11       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "12       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "13       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "14       UP Technologies Pvt. Ltd.            android dev      suri@mail.com   \n",
      "\n",
      "   Password   Specialisation_clean  \n",
      "0     abhi1                web dev  \n",
      "1      suri            android dev  \n",
      "2     sidhu      automobile design  \n",
      "3   prakash        mega structures  \n",
      "4      simi  computer architecture  \n",
      "5      agam        induction motor  \n",
      "6    kanish  communication systems  \n",
      "7     shail       machine learning  \n",
      "8       adi      automobile design  \n",
      "9      suri            android dev  \n",
      "10     suri            android dev  \n",
      "11     suri            android dev  \n",
      "12     suri            android dev  \n",
      "13     suri            android dev  \n",
      "14     suri            android dev  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.set_index('Name', inplace = True)\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(df['Specialisation_clean'])\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "indices = pd.Series(df.index)\n",
    "idx = 0\n",
    "def recommendations(name, cosine_similarities = cosine_similarities):\n",
    "    \n",
    "    recommended_profiles = []\n",
    "\n",
    "    # gettin the index of the hotel that matches the name\n",
    "    idx = indices[indices == name].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar hotels except itself\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    # populating the list with the names of the top 10 matching hotels\n",
    "    for i in top_10_indexes:\n",
    "        recommended_profiles.append(list(df.index)[i])\n",
    "        \n",
    "    return recommended_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
